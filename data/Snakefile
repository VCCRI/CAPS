from snakemake.remote.GS import RemoteProvider

GS = RemoteProvider(stay_on_remote=True)

###############################################################################
#                                  Main files                                 #
###############################################################################

# Files for CAPS ##############################################################
all_by_csq = GS.remote(config["gcp_rootdir"] + "by_csq.tsv")
all_by_csq_w_AF_AC = GS.remote(config["gcp_rootdir"] + "by_csq_w_AF_AC.tsv")
all_by_csq_genomes = GS.remote(config["gcp_rootdir"] + "by_csq_genomes.tsv")

# Files for analysis ##########################################################
# All QC-compliant synonymous variants, by LOEUF constraint level
syn_constrained = GS.remote(config["gcp_rootdir"] + "syn_constrained.tsv")
# Variants near canonical splice positions
near_splice_vars = GS.remote(config["gcp_rootdir"] + "near_splice_vars.tsv")
near_splice_vars_genomes = GS.remote(
    config["gcp_rootdir"] + "near_splice_vars_genomes.tsv"
)
# Canonical splice site variants with a binary (high/low) SpliceAI score
canonical_splice_site_vars = GS.remote(
    config["gcp_rootdir"] + "canonical_splice_site_vars.tsv"
)

# Whiffin2020 #################################################################

syn_by_context_Whiffin2020 = GS.remote(
    config["gcp_rootdir"] + "syn_by_context_Whiffin2020.tsv"
)
intronic_by_context_Whiffin2020 = GS.remote(
    config["gcp_rootdir"] + "intronic_by_context_Whiffin2020.tsv"
)

# AlphaMissense ###############################################################

missense_vars_with_alphamissense = GS.remote(
    config["gcp_rootdir"] + "missense_vars_with_alphamissense.tsv"
)

###############################################################################
#                               Auxiliary files                               #
###############################################################################

# LoF metrics (including LOEUF) by gene
lof_metrics_by_gene_file = GS.remote(config["gcp_rootdir"] + "lof_metrics_by_gene.txt")
# Mutability table
mutation_ht = GS.remote(config["gcp_rootdir"] + "mutation_ht.tsv")
# Pre-calculated SpliceAI scores (hg19)
spliceai_scores = GS.remote(config["spliceai_scores_path"])
# Pre-calculated AlphaMissense scores (hg19)
alphamissense_scores = GS.remote(config["alphamissense_scores_path"])

###############################################################################


rule all:
    input:
        mutation_ht,
        # Genomes #############################################################
        all_by_csq_genomes,
        # Exomes ##############################################################
        all_by_csq,
        syn_constrained,
        # Splicing ############################################################
        near_splice_vars,
        near_splice_vars_genomes,
        canonical_splice_site_vars,
        # Whiffin2020 #########################################################
        intronic_by_context_Whiffin2020,
        syn_by_context_Whiffin2020,
        # AlphaMissense #######################################################
        missense_vars_with_alphamissense,



rule mutation_ht:
    output:
        mutation_ht,
    run:
        import hail as hl

        mutation_ht = hl.read_table(config["mutation_rates_ht_path"])
        mutation_ht.export(output[0])


rule all_by_csq:
    output:
        all_by_csq,
    run:
        import hail as hl
        from preprocessing import preprocessing

        variants = preprocessing(
            config["exomes_ht_path"],
            config["context_ht_path"],
            config["mutation_rates_ht_path"],
            config["coverage_exomes_ht_path"],
            {"female": config["female_exomes"], "male": config["male_exomes"]},
        )

        variants.group_by(
            "context",
            "ref",
            "alt",
            "mu",
            "methylation_level",
            "worst_csq",
            "coverage",
        ).aggregate(
            variant_count=hl.agg.count(),
            singleton_count=hl.agg.count_where(variants.freq[0].AC == 1),
        ).export(
            output[0]
        )


rule all_by_csq_w_AF_AC:
    output:
        all_by_csq_w_AF_AC,
    run:
        import hail as hl
        from preprocessing import preprocessing

        variants = preprocessing(
            config["exomes_ht_path"],
            config["context_ht_path"],
            config["mutation_rates_ht_path"],
            config["coverage_exomes_ht_path"],
            {"female": config["female_exomes"], "male": config["male_exomes"]},
        )

        variants = variants.annotate(AF=variants.freq[0].AF)
        variants = variants.annotate(AC=variants.freq[0].AC)

        variants.group_by(
            "context",
            "ref",
            "alt",
            "mu",
            "methylation_level",
            "worst_csq",
            "coverage",
            "AF",
            "AC",
        ).aggregate(
            variant_count=hl.agg.count(),
            singleton_count=hl.agg.count_where(variants.freq[0].AC == 1),
        ).export(
            output[0]
        )


rule all_by_csq_genomes:
    output:
        all_by_csq_genomes,
    run:
        import hail as hl
        from preprocessing import preprocessing

        variants = preprocessing(
            config["genomes_ht_path"],
            config["context_ht_path"],
            config["mutation_rates_ht_path"],
            config["coverage_genomes_ht_path"],
            {"female": config["female_genomes"], "male": config["male_genomes"]},
        )
        variants.group_by(
            "context",
            "ref",
            "alt",
            "mu",
            "methylation_level",
            "worst_csq",
            "coverage",
        ).aggregate(
            variant_count=hl.agg.count(),
            singleton_count=hl.agg.count_where(variants.freq[0].AC == 1),
        ).export(
            output[0]
        )


# Constrained genes ###########################################################


rule download_LOEUF:
    output:
        lof_metrics_by_gene_file,
    shell:
        """
        wget -O lof_metrics_by_gene.txt.bgz {config[lof_metrics_by_gene]}
        gunzip -c lof_metrics_by_gene.txt.bgz > lof_metrics_by_gene.txt
        gsutil cp ./lof_metrics_by_gene.txt {output[0]}
        """


rule annotate_syn_constrained:
    input:
        lof_metrics_by_gene_file,
    output:
        syn_constrained,
    run:
        import hail as hl
        from preprocessing import preprocessing

        variants = preprocessing(
            config["exomes_ht_path"],
            config["context_ht_path"],
            config["mutation_rates_ht_path"],
            config["coverage_exomes_ht_path"],
            {"female": config["female_exomes"], "male": config["male_exomes"]},
        )

        syn_vars = variants.filter(
            (variants.worst_csq == "synonymous_variant") & (variants.coverage >= 30)
        )

        syn_vars = syn_vars.annotate(
            transcript_consequences=syn_vars.vep.transcript_consequences.find(
                lambda x: (x.consequence_terms == ["synonymous_variant"])
                & (x.biotype == "protein_coding")
            )
        )

        all_genes = hl.import_table(input[0])

        genes10 = all_genes.filter((all_genes.oe_lof_upper_bin == "0"))
        genes10 = hl.set(genes10.gene.collect())

        genes20 = all_genes.filter((all_genes.oe_lof_upper_bin == "1"))
        genes20 = hl.set(genes20.gene.collect())

        genes30 = all_genes.filter((all_genes.oe_lof_upper_bin == "2"))
        genes30 = hl.set(genes30.gene.collect())

        genes40 = all_genes.filter((all_genes.oe_lof_upper_bin == "3"))
        genes40 = hl.set(genes40.gene.collect())

        genes50 = all_genes.filter((all_genes.oe_lof_upper_bin == "4"))
        genes50 = hl.set(genes50.gene.collect())

        genes60 = all_genes.filter((all_genes.oe_lof_upper_bin == "5"))
        genes60 = hl.set(genes60.gene.collect())

        genes70 = all_genes.filter((all_genes.oe_lof_upper_bin == "6"))
        genes70 = hl.set(genes70.gene.collect())

        genes80 = all_genes.filter((all_genes.oe_lof_upper_bin == "7"))
        genes80 = hl.set(genes80.gene.collect())

        genes90 = all_genes.filter((all_genes.oe_lof_upper_bin == "8"))
        genes90 = hl.set(genes90.gene.collect())

        genes100 = all_genes.filter((all_genes.oe_lof_upper_bin == "9"))
        genes100 = hl.set(genes100.gene.collect())

        syn_vars = syn_vars.annotate(
            loeuf=hl.case()
            .when(genes10.contains(syn_vars.transcript_consequences.gene_symbol), 1)
            .when(genes20.contains(syn_vars.transcript_consequences.gene_symbol), 2)
            .when(genes30.contains(syn_vars.transcript_consequences.gene_symbol), 3)
            .when(genes40.contains(syn_vars.transcript_consequences.gene_symbol), 4)
            .when(genes50.contains(syn_vars.transcript_consequences.gene_symbol), 5)
            .when(genes60.contains(syn_vars.transcript_consequences.gene_symbol), 6)
            .when(genes70.contains(syn_vars.transcript_consequences.gene_symbol), 7)
            .when(genes80.contains(syn_vars.transcript_consequences.gene_symbol), 8)
            .when(genes90.contains(syn_vars.transcript_consequences.gene_symbol), 9)
            .when(genes100.contains(syn_vars.transcript_consequences.gene_symbol), 10)
            .or_missing()
        )

        syn_vars.group_by(
            "context", "ref", "alt", "methylation_level", "mu", "loeuf"
        ).aggregate(
            variant_count=hl.agg.count(),
            singleton_count=hl.agg.count_where(syn_vars.freq[0].AC == 1),
        ).export(
            output[0]
        )


###############################################################################


rule near_splice_vars:
    output:
        near_splice_vars,
    run:
        import hail as hl
        from preprocessing import preprocessing

        variants = preprocessing(
            config["exomes_ht_path"],
            config["context_ht_path"],
            config["mutation_rates_ht_path"],
            config["coverage_exomes_ht_path"],
            {"female": config["female_exomes"], "male": config["male_exomes"]},
        )

        # This selects canonical donor and acceptor positions
        splice_vars = variants.filter(
            (
                (variants.worst_csq == "splice_donor_variant")
                | (variants.worst_csq == "splice_acceptor_variant")
            )
            # In this pipeline, variants with reference alleles
            # "G"/"T" are replaced with "C"/"A" and marked
            # "was_flipped". To extract the positions of the last
            # intronic position for acceptors and first intronic
            # position for donors, we have to select those variants,
            # for which reference allele is "C" ("G" originally) and
            # "was_flipped" is True.
            & ((variants.ref == "C") & (variants.was_flipped == True))
        )

        # Take a 30bp window around each canonical splice position
        splice_vars = splice_vars.annotate(window=splice_vars.locus.window(30, 30))

        splice_vars = splice_vars.key_by(splice_vars.window)

        variants = variants.annotate(splice_type=splice_vars[variants.locus].worst_csq)
        # Filter out variants that don't fall within a near-splice region
        variants = variants.filter(hl.is_defined(variants.splice_type))
        variants = variants.annotate(
            splice_pos=splice_vars[variants.locus].locus.position
        )
        variants = variants.annotate(
            splice_distance=variants.locus.position - variants.splice_pos
        )

        variants.group_by(
            "context",
            "ref",
            "alt",
            "mu",
            "methylation_level",
            "worst_csq",
            "coverage",
            "splice_distance",
            "splice_type",
        ).aggregate(
            variant_count=hl.agg.count(),
            singleton_count=hl.agg.count_where(variants.freq[0].AC == 1),
        ).export(
            output[0]
        )


rule near_splice_vars_genomes:
    output:
        near_splice_vars_genomes,
    run:
        import hail as hl
        from preprocessing import preprocessing

        variants = preprocessing(
            config["genomes_ht_path"],
            config["context_ht_path"],
            config["mutation_rates_ht_path"],
            config["coverage_genomes_ht_path"],
            {"female": config["female_genomes"], "male": config["male_genomes"]},
        )

        # This selects canonical donor and acceptor positions
        splice_vars = variants.filter(
            (
                (variants.worst_csq == "splice_donor_variant")
                | (variants.worst_csq == "splice_acceptor_variant")
            )
            # In this pipeline, variants with reference alleles
            # "G"/"T" are replaced with "C"/"A" and marked
            # "was_flipped". To extract the positions of the last
            # intronic position for acceptors and first intronic
            # position for donors, we have to select those variants,
            # for which reference allele is "C" ("G" originally) and
            # "was_flipped" is True.
            & ((variants.ref == "C") & (variants.was_flipped == True))
        )

        # Take a 30bp window around each canonical splice position
        splice_vars = splice_vars.annotate(window=splice_vars.locus.window(30, 30))

        splice_vars = splice_vars.key_by(splice_vars.window)

        variants = variants.annotate(splice_type=splice_vars[variants.locus].worst_csq)
        # Filter out variants that don't fall within a near-splice region
        variants = variants.filter(hl.is_defined(variants.splice_type))
        variants = variants.annotate(
            splice_pos=splice_vars[variants.locus].locus.position
        )
        variants = variants.annotate(
            splice_distance=variants.locus.position - variants.splice_pos
        )

        variants.group_by(
            "context",
            "ref",
            "alt",
            "mu",
            "methylation_level",
            "worst_csq",
            "coverage",
            "splice_distance",
            "splice_type",
        ).aggregate(
            variant_count=hl.agg.count(),
            singleton_count=hl.agg.count_where(variants.freq[0].AC == 1),
        ).export(
            output[0]
        )


# Whiffin2020 #################################################################


rule syn_by_context_Whiffin2020:
    output:
        syn_by_context_Whiffin2020,
    run:
        import hail as hl
        from preprocessing import preprocessing

        variants = preprocessing(
            config["genomes_ht_path"],
            config["context_ht_path"],
            config["mutation_rates_ht_path"],
            config["coverage_genomes_ht_path"],
            {"female": config["female_genomes"], "male": config["male_genomes"]},
        )

        syn_vars = variants.filter(
            (variants.worst_csq == "synonymous_variant")
            & (variants.coverage > 15)
            & (variants.coverage < 60)
            & (variants.locus.contig != "X")
            & (variants.locus.contig != "Y")
        )

        syn_vars.group_by(
            "context",
            "ref",
            "alt",
            "mu",
            "methylation_level",
        ).aggregate(
            variant_count=hl.agg.count(),
            singleton_count=hl.agg.count_where(syn_vars.freq[0].AC == 1),
        ).export(
            output[0]
        )


rule intronic_by_context_Whiffin2020:
    output:
        intronic_by_context_Whiffin2020,
    run:
        import hail as hl
        from preprocessing import preprocessing

        variants = preprocessing(
            config["genomes_ht_path"],
            config["context_ht_path"],
            config["mutation_rates_ht_path"],
            config["coverage_genomes_ht_path"],
            {"female": config["female_genomes"], "male": config["male_genomes"]},
        )

        intron_vars = variants.filter(
            (variants.worst_csq == "intron_variant")
            & (variants.coverage > 15)
            & (variants.coverage < 60)
            & (variants.locus.contig != "X")
            & (variants.locus.contig != "Y")
        )

        intron_vars.group_by(
            "context",
            "ref",
            "alt",
            "mu",
            "methylation_level",
        ).aggregate(
            variant_count=hl.agg.count(),
            singleton_count=hl.agg.count_where(intron_vars.freq[0].AC == 1),
        ).export(
            output[0]
        )


# Splicing ####################################################################


rule canonical_splice_site_vars:
    input:
        spliceai_scores,
    output:
        canonical_splice_site_vars,
    run:
        import hail as hl
        from preprocessing import preprocessing

        variants = preprocessing(
            config["exomes_ht_path"],
            config["context_ht_path"],
            config["mutation_rates_ht_path"],
            config["coverage_exomes_ht_path"],
            {"female": config["female_exomes"], "male": config["male_exomes"]},
        )

        variants = variants.filter(
            (variants.worst_csq == "splice_acceptor_variant")
            | (variants.worst_csq == "splice_donor_variant")
        )

        spliceai = hl.import_vcf(input[0], force_bgz=True)
        spliceai = spliceai.make_table()
        spliceai = spliceai[variants.key]

        variants = variants.annotate(
            high_DS_AG=hl.if_else(spliceai.info.DS_AG >= 0.8, 1, 0),
            high_DS_AL=hl.if_else(spliceai.info.DS_AL >= 0.8, 1, 0),
            high_DS_DG=hl.if_else(spliceai.info.DS_DG >= 0.8, 1, 0),
            high_DS_DL=hl.if_else(spliceai.info.DS_DL >= 0.8, 1, 0),
        )

        variants.group_by(
            "context",
            "ref",
            "alt",
            "mu",
            "methylation_level",
            "worst_csq",
            "coverage",
            "high_DS_AG",
            "high_DS_AL",
            "high_DS_DG",
            "high_DS_DL",
        ).aggregate(
            variant_count=hl.agg.count(),
            singleton_count=hl.agg.count_where(variants.freq[0].AC == 1),
        ).export(
            output[0]
        )


# AlphaMissense ###############################################################


rule missense_vars_with_alphamissense:
    output:
        missense_vars_with_alphamissense,
    run:
        import hail as hl
        from preprocessing import preprocessing

        variants = preprocessing(
            config["exomes_ht_path"],
            config["context_ht_path"],
            config["mutation_rates_ht_path"],
            config["coverage_exomes_ht_path"],
            {"female": config["female_exomes"], "male": config["male_exomes"]},
        )

        variants = variants.filter(variants.worst_csq == "missense_variant")

        am = hl.import_table(
            config["alphamissense_scores_path"],
            find_replace=("chr", ""),
            types={"Start": hl.tint32, "End": hl.tint32, "AM_SCORE": hl.tfloat64},
        )
        am = am.key_by(
            locus=hl.locus(
                am["#Chr"],
                am.Start,
                "GRCh37",
            ),
            alleles=[am.Ref, am.Alt],
        )

        am = am[variants.key]
        variants = variants.annotate(AM_CLASS=am.AM_CLASS, AM_SCORE=am.AM_SCORE)

        variants = variants.annotate(AC=variants.freq[0].AC)

        variants.select(
            "context",
            "ref",
            "alt",
            "mu",
            "methylation_level",
            "worst_csq",
            "coverage",
            "AC",
            "AM_CLASS",
            "AM_SCORE",
        ).export(output[0])
